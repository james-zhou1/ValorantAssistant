{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backend.GEA_api_caller import *\n",
    "from Backend.GEA_classified import API_KEY\n",
    "import json\n",
    "\n",
    "from Backend.GEA_database_management import get_map_data_db\n",
    "from Backend.GEA_visualizations import plot_data_for_map\n",
    "from Backend.GEA_transformation_functions import analyze_individual, compile_match_data, get_ranked_matches\n",
    "from Backend.GEA_constants import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# leaderboard = get_leaderboard_info(API_KEY, 'na')\n",
    "\n",
    "# print(json.dumps(leaderboard, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "name = 'GEA OldAsian'\n",
    "tag = 'GEA'\n",
    "queue = 'competitive'\n",
    "\n",
    "\n",
    "\n",
    "puuid = get_puuid(name, tag, API_KEY)['data']['puuid']\n",
    "\n",
    "# start = 25\n",
    "# end = 29\n",
    "# response = get_raw(puuid, API_KEY,queue, startIndex = start, endIndex = end)\n",
    "\n",
    "\n",
    "\n",
    "# print(json.dumps(response, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr = get_ranked_matches(puuid, (9,12), set(), 100)\n",
    "\n",
    "print(json.dumps(arr, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_map_data_db('leaderboard_data_GEA', 'Ascent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joli_data = analyze_individual('GEA joli', 'brrr')\n",
    "# joli_data = compile_match_data([{'name':'GEA joli','tag': 'brrr'}], set())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Memory: 12.61 MB\n",
      "Used Memory (Human Readable): 12.60M\n",
      "flask_cache_27488932-3fd9-4476-b4f8-09269f50cf57: 9.3 MB, Expiration Time: 3256 seconds\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import redis\n",
    "import sys\n",
    "\n",
    "import redis\n",
    "\n",
    "r = redis.Redis(\n",
    "  host='redis-16449.c8.us-east-1-4.ec2.redns.redis-cloud.com',\n",
    "  port=16449,\n",
    "  password='RWzWWTRnBAvgHLv2R6jBHQltVuskWcA4')\n",
    "\n",
    "# # Connect to your Redis server\n",
    "# r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "# Convert bytes to appropriate unit\n",
    "def convert_bytes_to_readable(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return f\"{s} {size_name[i]}\"\n",
    "\n",
    "\n",
    "# Get memory information\n",
    "memory_info = r.info('memory')\n",
    "\n",
    "# Print memory usage details\n",
    "used_memory = memory_info['used_memory']\n",
    "used_memory_human = memory_info['used_memory_human']\n",
    "\n",
    "print(f\"Used Memory: {convert_bytes_to_readable(used_memory)}\")\n",
    "print(f\"Used Memory (Human Readable): {used_memory_human}\")\n",
    "\n",
    "\n",
    "# Get all keys in the current database\n",
    "keys = r.keys('*')\n",
    "\n",
    "# Print keys, size of their corresponding values, and expiration time\n",
    "for key in keys:\n",
    "    value = r.get(key)\n",
    "    value_size = sys.getsizeof(value) if value is not None else 0  # Get the size of the value in bytes\n",
    "    expiration_time = r.ttl(key)  # Get the expiration time in seconds\n",
    "\n",
    "    if value is not None:\n",
    "        print(f\"{key.decode('utf-8')}: {convert_bytes_to_readable(value_size)}, Expiration Time: {expiration_time} seconds\")\n",
    "    else:\n",
    "        print(f\"{key.decode('utf-8')}: None, Expiration Time: {expiration_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "\n",
    "\n",
    "print(str(uuid.uuid4()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Backend.GEA_visualizations import *\n",
    "\n",
    "def is_serializable(obj):\n",
    "    try:\n",
    "        pickle.dumps(obj)\n",
    "        return True\n",
    "    except (pickle.PicklingError, TypeError):\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "map_plotter = Map_Plotter('leaderboard_data_GEA', 'Ascent')\n",
    "if is_serializable(map_plotter):\n",
    "    print(\"map_plotter is serializable.\")\n",
    "else:\n",
    "    print(\"map_plotter is not serializable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backend.GEA_visualizations import *\n",
    "\n",
    "curr_map = Map_Plotter('leaderboard_data_GEA', 'Ascent')\n",
    "\n",
    "\n",
    "def buy_values(buy_name: str):\n",
    "    if(buy_name == 'pistol'):\n",
    "        return 0,1000\n",
    "    elif(buy_name == 'rifle'):\n",
    "        return 3900, 5000\n",
    "    elif(buy_name == 'all'):\n",
    "        return 0, 7950\n",
    "    elif(buy_name == 'fullbuy'):\n",
    "        return 3600, 7950\n",
    "    elif(buy_name == 'midbuy'):\n",
    "        return 1000, 3900\n",
    "    elif(buy_name == 'eco'):\n",
    "        return 0, 3000\n",
    "    elif(buy_name == 'operator'):\n",
    "        return 5750,7950\n",
    "\n",
    "a_lower, a_upper = buy_values('rifle') #ATTACKERS BUY\n",
    "\n",
    "d_lower, d_upper = buy_values('rifle') #DEFENDERS BUY\n",
    "\n",
    "\n",
    "attack_options = {\n",
    "    \"kills\": {\"lower\": a_lower//50, \"upper\": a_upper//50}, #between 0 160 \n",
    "    \"deaths\": {\"lower\": a_lower//50, \"upper\": a_upper//50}                  #note: MAKE KILLS AND DEATHS OPTIONS THE SAME(physically)\n",
    "\n",
    "}\n",
    "defense_options = {\n",
    "    \"kills\": {\"lower\": d_lower//50, \"upper\": d_upper//50}, #between 0 160\n",
    "    \"deaths\": {\"lower\": d_lower//50, \"upper\":d_upper//50}\n",
    "}\n",
    "\n",
    "\n",
    "attack = False\n",
    "defense = True\n",
    "\n",
    "print(curr_map)\n",
    "\n",
    "curr_map.update_buy_range_attack(attack_options)\n",
    "curr_map.update_buy_range_defense(defense_options)\n",
    "\n",
    "\n",
    "kills_bin = curr_map.generate_kills_bin(attack = attack,defense = defense)\n",
    "deaths_bin = curr_map.generate_deaths_bin(attack = attack,defense = defense)\n",
    "\n",
    "kills_heatmap_image = curr_map.create_plot(kills_bin,attack = attack,defense = defense,kill = True,death = False, log_scale=True, filter_sigma=2)\n",
    "deaths_heatmap_image  = curr_map.create_plot(deaths_bin,attack = attack,defense = defense,kill = False,death = True, log_scale=True, filter_sigma=2)\n",
    "\n",
    "combined = kills_bin + deaths_bin\n",
    "combined_heatmap_image = curr_map.create_plot(combined,attack = attack,defense = defense,kill = True,death = True, log_scale=True, filter_sigma=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_guide = curr_map.create_positioning_guide(kills_bin,deaths_bin, attack = attack, defense = defense, filter_sigma= 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Example data points\n",
    "data = np.random.randn(1000000, 2)\n",
    "\n",
    "# Define the grid size\n",
    "x_bins = np.linspace(-3, 3, 200)\n",
    "y_bins = np.linspace(-3, 3, 200)\n",
    "\n",
    "# Compute the histogram\n",
    "heatmap, xedges, yedges = np.histogram2d(data[:,0], data[:,1], bins=(x_bins, y_bins))\n",
    "heatmap = gaussian_filter(heatmap, sigma=0)\n",
    "# Plot the heatmap\n",
    "plt.imshow(heatmap.T, extent=[x_bins.min(), x_bins.max(), y_bins.min(), y_bins.max()], origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Generate random sample data\n",
    "np.random.seed(0)\n",
    "data = np.random.randn(10000, 2)\n",
    "\n",
    "# Adjustable parameters\n",
    "grid_size = 400  # Number of bins along each axis\n",
    "x_min, x_max = -3, 3  # Horizontal range of data\n",
    "y_min, y_max = -3, 3  # Vertical range of data\n",
    "normalize = False  # Whether to normalize the histogram values\n",
    "use_log_scale = True  # Whether to use logarithmic scale\n",
    "cmap_choice = 'inferno'  # Colormap for the heatmap\n",
    "interpolation_method = 'nearest'  # Interpolation method ('none', 'nearest', 'bilinear', etc.)\n",
    "apply_gaussian_filter = True  # Whether to apply Gaussian smoothing\n",
    "sigma = 4  # Standard deviation for Gaussian kernel\n",
    "\n",
    "# Binning (Histogram Method)\n",
    "start_time = time.time()\n",
    "x_bins = np.linspace(x_min, x_max, grid_size)\n",
    "y_bins = np.linspace(y_min, y_max, grid_size)\n",
    "heatmap_hist, _, _ = np.histogram2d(data[:, 0], data[:, 1], bins=(x_bins, y_bins))\n",
    "\n",
    "# Apply normalization if selected\n",
    "if normalize:\n",
    "    heatmap_hist = heatmap_hist / heatmap_hist.max()\n",
    "\n",
    "# Apply logarithmic scale if selected\n",
    "if use_log_scale:\n",
    "    heatmap_hist = np.log1p(heatmap_hist)  # log1p is used to avoid log(0) issues\n",
    "\n",
    "# Apply Gaussian filtering if selected\n",
    "if apply_gaussian_filter:\n",
    "    heatmap_hist = gaussian_filter(heatmap_hist, sigma=sigma)\n",
    "\n",
    "end_time = time.time()\n",
    "histogram_time = end_time - start_time\n",
    "\n",
    "# Kernel Density Estimation (KDE)\n",
    "start_time = time.time()\n",
    "kde = gaussian_kde(data.T, bw_method=0.1)\n",
    "x_grid, y_grid = np.meshgrid(np.linspace(x_min, x_max, grid_size), np.linspace(y_min, y_max, grid_size))\n",
    "z_kde = kde(np.vstack([x_grid.ravel(), y_grid.ravel()])).reshape(x_grid.shape)\n",
    "end_time = time.time()\n",
    "kde_time = end_time - start_time\n",
    "\n",
    "# Plotting the results\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].imshow(heatmap_hist.T, extent=[x_min, x_max, y_min, y_max], origin='lower')\n",
    "ax[0].set_title(f'Histogram Method (Time: {histogram_time:.4f}s)')\n",
    "\n",
    "im = ax[1].imshow(z_kde, extent=[x_min, x_max, y_min, y_max], origin='lower')\n",
    "ax[1].set_title(f'KDE (Time: {kde_time:.4f}s)')\n",
    "\n",
    "fig.suptitle(f\"Heatmap Generation Methods for {len(data)} Datapoints\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Generate random sample data\n",
    "np.random.seed(0)\n",
    "data = np.random.randn(100000, 2)\n",
    "\n",
    "# Adjustable parameters\n",
    "grid_size = 400  # Number of bins along each axis\n",
    "x_min, x_max = -3, 3  # Horizontal range of data\n",
    "y_min, y_max = -3, 3  # Vertical range of data\n",
    "normalize = False  # Whether to normalize the histogram values\n",
    "use_log_scale = True  # Whether to use logarithmic scale\n",
    "cmap_choice = 'viridis'  # Colormap for the heatmap\n",
    "interpolation_method = 'nearest'  # Interpolation method ('none', 'nearest', 'bilinear', etc.)\n",
    "apply_gaussian_filter = True  # Whether to apply Gaussian smoothing\n",
    "sigma = 3  # Standard deviation for Gaussian kernel\n",
    "\n",
    "# Binning (Histogram Method)\n",
    "x_bins = np.linspace(x_min, x_max, grid_size)\n",
    "y_bins = np.linspace(y_min, y_max, grid_size)\n",
    "heatmap_hist, _, _ = np.histogram2d(data[:, 0], data[:, 1], bins=(x_bins, y_bins))\n",
    "\n",
    "# Apply normalization if selected\n",
    "if normalize:\n",
    "    heatmap_hist = heatmap_hist / heatmap_hist.max()\n",
    "\n",
    "# Apply logarithmic scale if selected\n",
    "if use_log_scale:\n",
    "    heatmap_hist = np.log1p(heatmap_hist)  # log1p is used to avoid log(0) issues\n",
    "\n",
    "# Apply Gaussian filtering if selected\n",
    "if apply_gaussian_filter:\n",
    "    heatmap_hist = gaussian_filter(heatmap_hist, sigma=sigma)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.imshow(heatmap_hist.T, extent=[x_min, x_max, y_min, y_max], origin='lower',\n",
    "           cmap=cmap_choice, interpolation=interpolation_method)\n",
    "plt.colorbar(label='Density')  # Add colorbar with label\n",
    "# plt.title('Heatmap Visualization')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
